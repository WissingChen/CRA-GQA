# the config for current running
dataset:
  name: nextgqa
  csv_path: data/nextgqa
  features_path: data/nextqa/video_feature/CLIP_L
  vocab_path: 
  batch_size: 64
  num_thread_reader: 4
  qmax_words: 30
  amax_words: 38
  max_feats: 32
  # multi choice
  mc: 5
  a2id: 
  feat_type: CLIPL

model:
  name: tempclip
  baseline: NG+
  lan: RoBERTa
  lan_weight_path: "/data2/chenweixing/Other/VQA/roberta-base"
  feature_dim: 768
  word_dim: 768
  num_layers: 2
  num_heads: 8
  d_model: 768
  d_ff: 768
  dropout: 0.3
  vocab_size: 50265
  n_negs: 1
  prop_num: 1
  sigma: 9
  gamma: 1
  # control the overlap extent of different proposal, 0: no overlap, 1 no diversity
  lamb: 0.15
  # trade offf with video grounding loss
  vg_loss: 1
  # determine the best temporal proposal during inference
  vote: 0

optim:
  pipeline: tempclip
  optimizer: Adam
  loss: {"ce": {"vq":1, "vqa":1}}
  # gradient clipping
  clip: 12
  lr: 1.e-5
  weight_decay: 0
  epochs: 30
  save_period: 1
  lr_scheduler: warmup
  step_size: 1
  amsgrad: true

stat:
  monitor:
    mode: max
    metric: acc
    early_stop: 30
    vis: false
    display_port: 8099
  record_dir: ./output
  resume: # "output/CausalGQA_RefineT/checkpoint/model_best.pth"

misc:
  # the name only for this running, not the task
  running_name: 'TempCLIP/NextGQA'
  info: "Temp[CLIP] (NG+)"
  cuda: "1"
  seed: 2025
  
