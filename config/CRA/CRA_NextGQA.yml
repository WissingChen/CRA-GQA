# the config for current running
dataset:
  name: nextgqa
  csv_path: data/nextgqa
  features_path: data/nextqa/video_feature/CLIP_L
  causal_feature_path: data/nextgqa/causal_feature
  vocab_path: 
  batch_size: 64 #  48
  num_thread_reader: 4
  qmax_words: 30
  amax_words: 38
  max_feats: 32
  # multi choice
  mc: 5
  a2id: 
  feat_type: CLIPL

model:
  name: CRA
  baseline: refine
  lan: RoBERTa
  lan_weight_path: "/data2/chenweixing/Other/VQA/roberta-base"
  feature_dim: 768
  word_dim: 768
  num_layers: 2
  num_heads: 8
  d_model: 768
  d_ff: 768
  dropout: 0.3
  vocab_size: 50265
  n_negs: 1
  prop_num: 1
  sigma: 9
  gamma: 1
  # control the overlap extent of different proposal, 0: no overlap, 1 no diversity
  lamb: 0.15
  window_sizes: [1,3,5]
  time_penalty: # 0.1
  do: true # causal intervention
  # trade offf with video grounding loss
  vg_loss: 1
  # determine the best temporal proposal during inference
  vote: 0

optim:
  pipeline: cra
  optimizer: Adam
  loss: {"ce": {"vq":1, "vqa":1}, "align": {"g": 0.5}}
  # gradient clipping
  clip: 12
  lr: 1.e-5
  weight_decay: 0
  epochs: 30
  save_period: 1
  # lr_scheduler: if warmup, the step will be 
  lr_scheduler: warmup
  step_size: 1
  amsgrad: true

stat:
  monitor:
    mode: max
    metric: acc
    early_stop: 30
    vis: false
    display_port: 8099
  record_dir: ./output
  resume: # "output/CI/NextGQA/CI_Vis/checkpoint/model_best.pth"

misc:
  # the name only for this running, not the task
  running_name: 'CRA/NextGQA/CRA'
  info: "Temp[CLIP] (CRA)" # add_Linguistic_BDI" add_Visual_FDI
  cuda: "1"
  seed: 1234
  
